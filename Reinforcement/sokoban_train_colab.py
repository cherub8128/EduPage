# Colab ì…€ 1
# ë“œë¼ì´ë¸Œ ë§ˆìš´íŠ¸í•˜ê¸°
from google.colab import drive
drive.mount('/content/drive')

# Colab ì…€ 2
# í•„ìš”í•œ ëª¨ë“ˆ ì„¤ì¹˜
!pip install "stable-baselines3[extra]>=2.0.0a5" gymnasium pygame > /dev/null 2>&1

# Colab ì…€ 3
# í˜„ì¬ ì‘ì—… í´ë”ë¥¼ ê¸°ë³¸ë¡œ ê²½ë¡œ ì¶”ê°€í•˜ê¸°
import sys
project_path = '/content/drive/MyDrive/Sokoban'
if project_path not in sys.path:
    sys.path.append(project_path)
    print(f"'{project_path}' ê²½ë¡œê°€ sys.pathì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.")

# Colab ì…€ 4
# AI í›ˆë ¨ì‹œí‚¤ê¸°
import os
import torch
import torch.nn as nn
from gymnasium import spaces

from stable_baselines3 import PPO
from stable_baselines3.common.monitor import Monitor
from stable_baselines3.common.vec_env import DummyVecEnv
from stable_baselines3.common.torch_layers import BaseFeaturesExtractor
from stable_baselines3.common.callbacks import CheckpointCallback

# í˜„ì¬ ê²½ë¡œì— ìˆëŠ” ì»¤ìŠ¤í…€ ëª¨ë“ˆë“¤ì„ import í•©ë‹ˆë‹¤.
from rnd_wrapper import RNDRewardWrapper 
from sokoban_env import SokobanEnv

# ------------------------------------------------------------------------------
# 1. CustomCNN í´ë˜ìŠ¤ ì •ì˜
# ëª¨ë¸ì„ ì €ì¥í•˜ê³  ë¶ˆëŸ¬ì˜¬ ë•Œ ì¼ê´€ì„±ì„ ìœ ì§€í•˜ê¸° ìœ„í•´ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ì— ì§ì ‘ ì •ì˜í•©ë‹ˆë‹¤.
# ------------------------------------------------------------------------------
class CustomCNN(BaseFeaturesExtractor):
    def __init__(self, observation_space: spaces.Box, features_dim: int = 128):
        super().__init__(observation_space, features_dim)
        n_input_channels = observation_space.shape[0]
        self.cnn = nn.Sequential(
            nn.Conv2d(n_input_channels, 32, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.Flatten(),
        )
        with torch.no_grad():
            n_flatten = self.cnn(
                torch.as_tensor(observation_space.sample()[None]).float()
            ).shape[1]
        self.linear = nn.Sequential(nn.Linear(n_flatten, features_dim), nn.ReLU())

    def forward(self, observations: torch.Tensor) -> torch.Tensor:
        return self.linear(self.cnn(observations))

# ------------------------------------------------------------------------------
# 2. í™˜ê²½ ìƒì„± í—¬í¼ í•¨ìˆ˜
# ------------------------------------------------------------------------------
def make_env(log_dir):
    def _init():
        env = SokobanEnv()
        # RND ë˜í¼ë¥¼ ì ìš©í•˜ì—¬ íƒí—˜ ë³´ìƒì„ ì¶”ê°€í•©ë‹ˆë‹¤.
        env = RNDRewardWrapper(env, lr=1e-4, feature_dim=128, intrinsic_reward_coef=0.001)
        # Monitor ë˜í¼ë¡œ ê°ì‹¸ í…ì„œë³´ë“œì— ë³´ìƒ ë“±ì„ ê¸°ë¡í•©ë‹ˆë‹¤.
        env = Monitor(env, log_dir)
        return env
    return _init

# ------------------------------------------------------------------------------
# 3. ë©”ì¸ í•™ìŠµ ë¡œì§
# ------------------------------------------------------------------------------
if __name__ == '__main__':
    # --- ê²½ë¡œ ì„¤ì • ---
    log_dir = "sokoban_logs/"
    tensorboard_log_dir = "sokoban_tensorboard/"
    model_save_path = "sokoban_models/"

    os.makedirs(log_dir, exist_ok=True)
    os.makedirs(tensorboard_log_dir, exist_ok=True)
    os.makedirs(model_save_path, exist_ok=True)

    # --- í™˜ê²½ ìƒì„± ---
    env = DummyVecEnv([make_env(log_dir)])

    # --- ì •ì±… ì„¤ì • ---
    policy_kwargs = dict(
        features_extractor_class=CustomCNN,
        features_extractor_kwargs=dict(features_dim=128),
    )

    # --- ëª¨ë¸ ë¡œë“œ ë˜ëŠ” ìƒˆë¡œ ìƒì„± ---
    final_model_path = os.path.join(model_save_path, "sokoban_final_model.zip")

    if os.path.exists(final_model_path):
        # ìµœì¢… ëª¨ë¸ íŒŒì¼ì´ ì¡´ì¬í•˜ë©´ ë¶ˆëŸ¬ì™€ì„œ í•™ìŠµì„ ì´ì–´ê°‘ë‹ˆë‹¤.
        print(f"'{final_model_path}' ì—ì„œ ê¸°ì¡´ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤. ì´ì–´ì„œ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.")
        model = PPO.load(final_model_path, env=env, tensorboard_log=tensorboard_log_dir)
    else:
        # ìµœì¢… ëª¨ë¸ íŒŒì¼ì´ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.
        print("ì €ì¥ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ì²˜ìŒë¶€í„° í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.")
        model = PPO(
            "CnnPolicy",
            env,
            policy_kwargs=policy_kwargs,
            verbose=1,
            tensorboard_log=tensorboard_log_dir,
            learning_rate=3e-4,
            n_steps=2048,
            batch_size=128,
            n_epochs=10,
            gamma=0.99,
            ent_coef=0.01,
        )
    
    # --- ì½œë°± ì„¤ì • (ì£¼ê¸°ì  ëª¨ë¸ ì €ì¥) ---
    checkpoint_callback = CheckpointCallback(
        save_freq=50000,
        save_path=model_save_path,
        name_prefix="sokoban_checkpoint_model"
    )

    # --- í•™ìŠµ ì‹¤í–‰ ---
    # â—â—â— ì—¬ê¸°ì„œ ì›í•˜ëŠ” í•™ìŠµëŸ‰ì„ ì„¤ì •í•˜ì„¸ìš”. â—â—â—
    TOTAL_TIMESTEPS = 5_000_000
    
    print(f"--- {TOTAL_TIMESTEPS:,} íƒ€ì„ìŠ¤í… í•™ìŠµ ì‹œì‘ ---")
    model.learn(
        total_timesteps=TOTAL_TIMESTEPS,
        callback=checkpoint_callback,
        progress_bar=True,
        reset_num_timesteps=False # Trueì´ë©´ ìƒˆë¡œ í•™ìŠµ, Falseì´ë©´ ì´ì–´ì„œ í•™ìŠµ
    )

    # --- ìµœì¢… ëª¨ë¸ ì €ì¥ ---
    # í•­ìƒ ê°™ì€ ì´ë¦„ìœ¼ë¡œ ì €ì¥í•˜ì—¬ ë‹¤ìŒ ì‹¤í–‰ ì‹œ ì´ì–´í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.
    model.save(final_model_path)
    
    env.close()

    # --- ì™„ë£Œ ë©”ì‹œì§€ ---
    print("\n" + "="*50)
    print("ğŸ‰ í•™ìŠµì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    print(f"ìµœì¢… ëª¨ë¸ì€ '{final_model_path}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print("í•™ìŠµ ê³¼ì •ì„ í™•ì¸í•˜ë ¤ë©´ ì•„ë˜ ëª…ë ¹ì–´ë¥¼ í„°ë¯¸ë„ì— ì…ë ¥í•˜ì„¸ìš”:")
    print(f"tensorboard --logdir={tensorboard_log_dir}")
    print("="*50)