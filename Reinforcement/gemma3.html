<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Gemma 3 1B IT 로컬 PC에서 실행하기</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;700;900&family=Noto+Sans+KR:wght@400;700&family=Fira+Code&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', 'Noto Sans KR', sans-serif;
            background: #111827;
            background: radial-gradient(circle at top left, rgba(17, 24, 39, 1) 0%, rgba(55, 48, 163, 0.2) 100%), #111827;
            color: #E5E7EB;
            overflow-y: scroll;
        }
        .slide {
            display: none;
            opacity: 0;
            transition: opacity 0.6s ease-in-out;
        }
        .slide.active {
            display: block;
            opacity: 1;
        }
        .code-highlight {
            background-color: rgba(139, 92, 246, 0.2);
            border-left: 2px solid #8B5CF6;
            display: block;
            margin: -0.5rem -1rem;
            padding: 0.5rem 1rem;
        }
        .code-wrapper {
            position: relative;
        }
        pre[class*="language-"] {
            border-radius: 0.5rem;
            border: 1px solid rgba(255, 255, 255, 0.1);
            background-color: #1F2937 !important;
            box-shadow: 0 4px 6px rgba(0,0,0,0.2);
            padding-top: 3.5rem !important;
        }
        .copy-btn {
            position: absolute;
            top: 0.75rem;
            right: 0.75rem;
            background-color: #374151;
            color: #D1D5DB;
            border: 1px solid #4B5563;
            border-radius: 0.375rem;
            padding: 0.35rem 0.75rem;
            font-size: 0.875rem;
            display: flex;
            align-items: center;
            gap: 0.5rem;
            cursor: pointer;
            transition: all 0.2s ease;
            z-index: 10;
        }
        .copy-btn:hover {
            background-color: #4B5563;
            color: #FFF;
        }
        .copy-btn.copied {
            background-color: #10B981;
            color: white;
            border-color: #059669;
        }

        .explanation-box {
            background-color: rgba(31, 41, 55, 0.7);
            border-left: 4px solid #6366F1;
            padding: 1.25rem;
            border-radius: 0.5rem;
            margin-top: 1rem;
            backdrop-filter: blur(10px);
        }
        .terminal {
            background-color: #000;
            color: #E5E7EB;
            padding: 1.25rem;
            border-radius: 0.5rem;
            font-family: 'Fira Code', monospace;
            border: 1px solid rgba(255,255,255,0.2);
            box-shadow: 0 10px 30px rgba(0,0,0,0.3);
        }
        .terminal .prompt { color: #4ade80; }
        .terminal .user-input { color: #60a5fa; }
        .terminal .output { color: #f87171; }

        .btn-gradient {
            background-image: linear-gradient(to right, #4F46E5, #8B5CF6);
            transition: all 0.3s ease;
            box-shadow: 0 4px 15px 0 rgba(79, 70, 229, 0.75);
        }
        .btn-gradient:hover {
            transform: translateY(-2px);
            box-shadow: 0 10px 20px rgba(79, 70, 229, 0.4);
        }
        
        #progress-bar-inner {
            transition: width 0.3s ease-in-out;
        }

        /* --- Custom PrismJS Theme for Readability --- */
        pre[class*="language-"] code[class*="language-"] {
            font-family: 'Fira Code', monospace;
        }

        :not(pre) > code[class*="language-"], pre[class*="language-"] {
             background: #1F2937;
        }

        .token.comment, .token.prolog, .token.doctype, .token.cdata { color: #6B7280; }
        .token.punctuation { color: #9CA3AF; }
        .token.property, .token.tag, .token.boolean, .token.number, .token.constant, .token.symbol, .token.deleted { color: #FBBF24; }
        .token.selector, .token.attr-name, .token.string, .token.char, .token.builtin, .token.inserted { color: #A7F3D0; }
        .token.operator, .token.entity, .token.url, .language-css .token.string, .style .token.string { color: #93C5FD; }
        .token.atrule, .token.attr-value, .token.keyword { color: #C4B5FD; }
        .token.function, .token.class-name { color: #818CF8; }
        .token.regex, .token.important, .token.variable { color: #FDBA74; }
        pre[class*="language-"], code[class*="language-"] {
            color: #E5E7EB;
            text-shadow: none;
        }
    </style>
</head>
<body class="p-4 md:p-8 flex items-center justify-center min-h-screen">

    <div class="max-w-7xl w-full mx-auto bg-gray-900/50 rounded-2xl shadow-2xl overflow-hidden border border-gray-700 backdrop-filter backdrop-blur-xl">
        
        <div id="progress-bar-container" class="w-full bg-gray-700 h-2 rounded-t-2xl">
            <div id="progress-bar-inner" class="bg-gradient-to-r from-indigo-500 to-purple-500 h-2"></div>
        </div>

        <div class="p-8 text-center">
            <h1 class="text-4xl md:text-5xl font-black text-transparent bg-clip-text bg-gradient-to-r from-indigo-400 to-purple-400">Gemma 3 1B IT 로컬 실행 가이드</h1>
            <p class="text-gray-400 mt-3 text-lg">당신의 PC에서 직접 최신 AI 모델을 다운로드하고 실행해보세요!</p>
        </div>

        <div id="slider-container" class="p-4 md:p-8 border-t border-gray-700 min-h-[550px]">
            <!-- Slides will be injected here by JS -->
        </div>

        <div class="bg-gray-900/70 p-4 flex justify-between items-center border-t border-gray-700">
            <button id="prevBtn" class="bg-gray-700 hover:bg-gray-600 text-white font-bold py-2 px-6 rounded-lg transition duration-300 disabled:opacity-40 disabled:cursor-not-allowed">이전</button>
            <div id="slide-counter" class="text-white text-lg font-semibold"></div>
            <button id="nextBtn" class="btn-gradient text-white font-bold py-2 px-6 rounded-lg">다음</button>
        </div>
    </div>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
    <script>
        const slides = [
            {
                title: "Step 1: 필요한 라이브러리 설치",
                explanation: `
                    <p>가장 먼저, PC의 터미널을 열고 Gemma 3 실행에 필요한 도구들을 설치합니다.</p>
                    <div class="explanation-box">
                        <p class="text-indigo-300"><strong>핵심 라이브러리:</strong><br>
                        - <code class="font-bold text-white">huggingface-hub:</code> 모델 다운로드 담당<br>
                        - <code class="font-bold text-white">transformers, torch:</code> 모델 실행 담당</p>
                    </div>
                    <p class="mt-4">터미널에 아래 명령어를 한 번에 복사하여 실행하세요.</p>
                `,
                code: `pip install transformers torch huggingface-hub`,
                language: 'bash'
            },
            {
                title: "Step 2: Hugging Face 로그인 및 토큰 발급",
                explanation: `
                    <p>최신 모델을 다운로드하려면 Hugging Face 계정이 필요합니다. <a href="https://huggingface.co/join" target="_blank" class="text-indigo-400 hover:underline font-bold">Hugging Face에 가입</a>한 후, 모델 접근 권한이 있는 'Access Token'을 발급받아야 합니다.</p>
                    <div class="explanation-box">
                        <p class="text-indigo-300"><strong>토큰 발급 (Read 권한):</strong><br>
                        1. 로그인 후, 프로필 > <strong>Settings</strong> > <strong>Access Tokens</strong> 탭으로 이동<br>
                        2. <strong>New token</strong> 버튼 클릭<br>
                        3. 이름(Name)을 정하고, 역할(Role)을 <strong>read</strong>로 선택 후 생성</p>
                    </div>
                    <p class="mt-4">생성된 토큰을 복사한 뒤, 아래 명령어를 터미널에 입력하여 로그인을 완료하세요. 토큰을 붙여넣고 엔터를 누르면 로그인되며, 입력하는 내용은 보이지 않습니다.</p>
                `,
                code: `huggingface-cli login`,
                language: 'bash'
            },
            {
                title: "Step 3: 모델 스펙과 입출력 형식 파악",
                explanation: `
                    <p>코드를 작성하기 전, <a href="https://huggingface.co/google/gemma-3-1b-it" target="_blank" class="text-indigo-400 hover:underline font-bold">모델 페이지</a>에서 모델의 사양과 사용법을 확인하는 것이 중요합니다. 특히 모델이 어떤 형식의 입력을 받고(Input), 어떤 형식으로 답변을 돌려주는지(Output) 파악해야 합니다.</p>
                     <div class="explanation-box">
                        <p class="text-indigo-300"><strong>gemma-3-1b-it 모델의 특징:</strong><br>
                        - <strong>입력(Input):</strong> 텍스트 외에 이미지도 이해할 수 있습니다. 1B 모델 기준, 최대 <strong>32,000 토큰</strong>(약 24,000 단어)의 긴 문맥을 기억합니다.<br>
                        - <strong>출력(Output):</strong> 입력에 대한 답변으로 텍스트를 생성하며, 최대 <strong>8,192 토큰</strong>(약 6,000 단어)까지 생성 가능합니다.<br>
                        - <strong>대화 형식:</strong> 'role'과 'content' 키를 가진 딕셔너리의 리스트 형태를 사용합니다.<br>
                        - <strong>역할(Role):</strong> 사용자는 <code class="font-bold text-white">'user'</code>, 모델은 <code class="font-bold text-white">'assistant'</code>로 지정하여 대화 문맥을 알려줍니다.
                        </p>
                    </div>
                    <p class="mt-4">이런 규칙을 이해해야 챗봇 코드의 <code class="bg-gray-700 p-1 rounded text-white">messages</code> 리스트를 올바르게 다룰 수 있습니다.</p>
                `,
                code: ``
            },
            {
                title: "Step 4: 스크립트 #1 - 모델 다운로드",
                explanation: `
                    <p>첫 번째 스크립트는 Hugging Face에서 Gemma 3 모델 파일을 내 PC로 다운로드하는 역할을 합니다.</p>
                    <p class="mt-2">아래 코드를 <code class="bg-gray-700 p-1 rounded text-white">model.py</code> 라는 이름으로 저장하세요. 모델은 약 5GB 이상이므로 충분한 공간을 확보해주세요.</p>
                `,
                code: `
# filename: model.py
from huggingface_hub import snapshot_download
import os

# Model ID to download
model_id = "google/gemma-3-1b-it"

# Local folder path to save the model
local_model_path = "./google/gemma-3-1b-it"

if not os.path.exists(local_model_path):
    os.makedirs(local_model_path)

print(f"Starting download of model '{model_id}'...")
print(f"Saving to: '{local_model_path}'")

snapshot_download(
    repo_id=model_id,
    local_dir=local_model_path,
    local_dir_use_symlinks=False
)

print(f"\\nDownload complete!")
                `,
                language: 'python'
            },
             {
                title: "Step 5: 스크립트 #2 - 로컬 챗봇 실행",
                explanation: `
                    <p>이제 다운로드한 모델을 사용하여 대화하는 챗봇 스크립트를 만들 차례입니다. 답변의 스타일을 조절할 수 있는 파라미터들이 추가되었습니다.</p>
                    <p class="mt-2">아래 코드를 <code class="bg-gray-700 p-1 rounded text-white">chatbot.py</code> 라는 이름으로 저장하세요. 다음 페이지에서 각 파라미터의 역할을 자세히 알아봅니다.</p>
                `,
                code: `
# filename: chatbot.py
import torch
from transformers import pipeline
import os

# 1. Path to the downloaded local model
local_model_path = "./google/gemma-3-1b-it"

# 2. Create a pipeline with the offline model
print("Creating a pipeline with the local model...")
pipe = pipeline(
    "text-generation",
    model=local_model_path,
    device="cuda", # Use GPU
    dtype=torch.float32,
)
print("Pipeline created! Starting chat.")

# 3. List to store conversation history
messages = []

# 4. Console chat loop
while True:
    user_input = input("You: ")
    if user_input.lower() in ["exit", "quit"]:
        break
    
    messages.append({"role": "user", "content": user_input})
    
    # Generate a response with parameters
    outputs = pipe(
        messages,
<span class="code-highlight">        max_new_tokens=512,
        do_sample=True,
        temperature=0.7,
        top_k=50,
        top_p=0.95</span>
    )
    
    assistant_response = outputs[0]["generated_text"][-1]["content"].strip()
    print(f"Assistant: {assistant_response}")
    
    # Update history to maintain context
    messages = outputs[0]["generated_text"]
                `,
                language: 'python'
            },
            {
                title: "Step 6: 실행 및 AI와 대화하기",
                explanation: `
                    <p>모든 준비가 끝났습니다! 터미널에서 스크립트를 순서대로 실행하여 AI 챗봇을 만나보세요.</p>
                    <p class="mt-2">1. <code class="bg-gray-700 p-1 rounded text-white">model.py</code>를 실행하여 모델 다운로드 (최초 1회)<br>
                    2. 다운로드 완료 후, <code class="bg-gray-700 p-1 rounded text-white">chatbot.py</code>를 실행하여 챗봇 시작</p>
                    <div class="terminal mt-4">
                        <span class="prompt">$</span> <span class="user-input">python model.py</span>
                        <div class="output">'google/gemma-3-1b-it' model download starts...</div>
                        <br>
                        <span class="prompt">$</span> <span class="user-input">python chatbot.py</span>
                    </div>
                    <div class="explanation-box">
                        <p class="text-indigo-300"><strong>Chatbot Execution Example:</strong></p>
                    </div>
                    <div class="terminal mt-4">
                        <div>Creating pipeline with local model...</div>
                        <div>Pipeline created! Starting chat.</div>
                        <div><span class="prompt">You:</span> <span class="user-input">Hi! Who are you?</span></div>
                        <div><span class="output">Assistant: Hello! I am a large language model trained by Google.</span></div>
                        <div><span class="prompt">You:</span> <span class="user-input">quit</span></div>
                    </div>
                `,
                code: ``
            },
             {
                title: "Step 7: AI의 답변 스타일 조절하기 (Parameters)",
                explanation: `
                    <p>AI의 답변은 여러 파라미터를 조절하여 원하는 스타일로 만들 수 있습니다. 챗봇의 창의성, 답변 길이, 정확성 등을 직접 튜닝해보세요.</p>
                     <div class="explanation-box">
                        <p class="text-indigo-300"><strong>주요 생성 파라미터:</strong><br>
                        - <code class="font-bold text-white">max_new_tokens:</code> 답변의 <strong>최대 길이</strong>를 정합니다. (단위: 토큰)<br>
                        - <code class="font-bold text-white">do_sample=True:</code> <strong>창의적 샘플링 모드</strong>를 켭니다. 챗봇처럼 자유로운 답변에 필수적입니다.<br>
                        - <code class="font-bold text-white">temperature:</code> <strong>창의성</strong>을 조절합니다. 값이 낮을수록(예: 0.2) 논리적이고 예측 가능한 답변을, 높을수록(예: 0.9) 무작위하고 독창적인 답변을 합니다.<br>
                        - <code class="font-bold text-white">top_k:</code> 다음 단어 후보를 가장 확률 높은 <strong>k개</strong>로 제한하여 문장의 일관성을 유지합니다.<br>
                        - <code class="font-bold text-white">top_p:</code> 확률의 합이 <strong>p</strong>가 되는 단어 후보 중에서만 선택하여, 어색한 단어가 나올 확률을 줄입니다.
                        </p>
                    </div>
                    <p class="mt-4"><code class="bg-gray-700 p-1 rounded text-white">chatbot.py</code> 코드의 이 부분을 수정하며 여러 가지 값을 테스트해보세요.</p>
                `,
                code: `
# Control the output style by adjusting these parameters
outputs = pipe(
    messages,
    max_new_tokens=512,      # Max length of the answer
    do_sample=True,          # Enable creative mode
    temperature=0.7,         # Creativity (0.2: logical, 0.9: random)
    top_k=50,                # Narrows choices to top k words
    top_p=0.95               # Narrows choices based on probability
)
                `,
                language: 'python'
            },
            {
                title: "Tip: 더 가벼운 모델 사용하기 (270M)",
                explanation: `
                    <p>1B 모델(약 5GB) 다운로드가 인터넷 환경이나 PC 사양 때문에 부담스럽다면, 훨씬 가벼운 270M 모델(약 500MB)을 사용할 수 있습니다.</p>
                     <div class="explanation-box">
                        <p class="text-indigo-300"><strong>gemma-3-270m-it model</strong>은 성능은 조금 낮지만 훨씬 빠르게 다운로드하고 실행할 수 있어 테스트용으로 좋습니다. 다음 슬라이드에서 270M 모델용 코드를 확인하세요.</p>
                    </div>
                `,
                code: ``,
            },
            {
                title: "Tip: 270M 모델 다운로드 스크립트",
                explanation: `
                    <p>아래와 같이 <code class="bg-gray-700 p-1 rounded text-white">model.py</code> 파일의 <code class="bg-gray-700 p-1 rounded text-white">model_id</code>와 <code class="bg-gray-700 p-1 rounded text-white">local_model_path</code>를 <code class="bg-gray-700 p-1 rounded text-white">google/gemma-3-270m-it</code>로 수정하여 실행하세요.</p>
                `,
                code: `
# filename: model_270m.py (saving as a new file is recommended)
from huggingface_hub import snapshot_download
import os

# Change the model ID to download
<span class="code-highlight">model_id = "google/gemma-3-270m-it"</span>

# Change the local folder path to save
<span class="code-highlight">local_model_path = "./google/gemma-3-270m-it"</span>

if not os.path.exists(local_model_path):
    os.makedirs(local_model_path)

print(f"Starting download of model '{model_id}'...")
print(f"Saving to: '{local_model_path}'")

snapshot_download(
    repo_id=model_id,
    local_dir=local_model_path,
    local_dir_use_symlinks=False
)

print(f"\\nDownload complete!")
                `,
                language: 'python'
            },
            {
                title: "Tip: 270M 모델 챗봇 실행 스크립트",
                explanation: `
                     <p>270M 모델을 다운로드했다면, <code class="bg-gray-700 p-1 rounded text-white">chatbot.py</code>의 <code class="bg-gray-700 p-1 rounded text-white">local_model_path</code>도 270M 모델 경로로 맞춰주어야 합니다.</p>
                `,
                code: `
# filename: chatbot_270m.py (saving as a new file is recommended)
import torch
from transformers import pipeline
import os

# 1. Change path to the downloaded 270M model
<span class="code-highlight">local_model_path = "./google/gemma-3-270m-it"</span>

# 2. Create a pipeline with the offline model
print("Creating a pipeline with the local model (270M)...")
pipe = pipeline(
    "text-generation",
    model=local_model_path,
    device="cuda",
    dtype=torch.float32,
)
print("Pipeline created! Starting chat.")

# ... (The rest of the chat loop code is the same)
                `,
                language: 'python'
            },
            {
                title: "Final Step: 나만의 모델 탐험하기",
                explanation: `
                    <p>이제 여러분은 로컬 PC에서 AI 모델을 직접 실행하는 방법을 배웠습니다!</p>
                    <p class="mt-2"><a href='https://huggingface.co/models' target='_blank' class='text-indigo-400 hover:underline font-bold'>Hugging Face Models</a>에는 Gemma 외에도 수많은 언어 모델이 있습니다.</p>
                    <div class="explanation-box">
                        <p class="text-indigo-300">마음에 드는 다른 모델을 찾아 <code class="bg-gray-700 p-1 rounded text-white">model.py</code>의 <code class="bg-gray-700 p-1 rounded text-white">model_id</code>를 수정해서 직접 다운로드하고 실행해보세요. 자신만의 AI 챗봇을 만드는 멋진 경험이 될 겁니다.</p>
                    </div>
                `,
                code: ``
            }
        ];

        let currentSlide = 0;
        const sliderContainer = document.getElementById('slider-container');
        const prevBtn = document.getElementById('prevBtn');
        const nextBtn = document.getElementById('nextBtn');
        const slideCounter = document.getElementById('slide-counter');
        const progressBar = document.getElementById('progress-bar-inner');

        function createSlide(slideData, index) {
            const slideElement = document.createElement('div');
            slideElement.className = 'slide p-4';
            slideElement.dataset.index = index;

            let codeHtml = '';
            if (slideData.code) {
                const tempDiv = document.createElement('div');
                const codeWithPlaceholders = slideData.code.trim()
                    .replace(/<span class="code-highlight">/g, '[[HIGHLIGHT_START]]')
                    .replace(/<\/span>/g, '[[HIGHLIGHT_END]]');
                
                tempDiv.textContent = codeWithPlaceholders;
                
                const finalCode = tempDiv.innerHTML
                    .replace(/\[\[HIGHLIGHT_START\]\]/g, '<span class="code-highlight">')
                    .replace(/\[\[HIGHLIGHT_END\]\]/g, '</span>');

                codeHtml = `
                    <div class="mt-6 code-wrapper">
                         <button class="copy-btn">
                            <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" viewBox="0 0 16 16">
                                <path d="M4 1.5H3a2 2 0 0 0-2 2v8a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2v-8a2 2 0 0 0-2-2h-1v1h1a1 1 0 0 1 1 1v8a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1v-8a1 1 0 0 1 1-1h1z"/>
                                <path d="M10.5 1.5a.5.5 0 0 1 .5-.5h2a.5.5 0 0 1 0 1h-2a.5.5 0 0 1-.5-.5m-5 0a.5.5 0 0 1 .5-.5h2a.5.5 0 0 1 0 1h-2a.5.5 0 0 1-.5-.5"/>
                            </svg>
                            <span class="copy-text">Copy</span>
                        </button>
                        <pre class="language-${slideData.language || 'python'}"><code class="language-${slideData.language || 'python'}">${finalCode}</code></pre>
                    </div>
                `;
            }

            slideElement.innerHTML = `
                <div class="grid grid-cols-1 ${slideData.code ? 'lg:grid-cols-2' : ''} gap-8 items-start">
                    <div class="prose prose-invert max-w-none prose-p:text-gray-300 prose-a:text-indigo-400 prose-headings:text-white">
                        <h2 class="text-3xl font-bold mb-4">${slideData.title}</h2>
                        <div class="leading-relaxed space-y-3">${slideData.explanation}</div>
                    </div>
                    ${slideData.code ? `<div>${codeHtml}</div>` : ''}
                </div>
            `;
            return slideElement;
        }

        function addCopyFunctionality() {
            document.querySelectorAll('.copy-btn').forEach(button => {
                button.addEventListener('click', () => {
                    const code = button.nextElementSibling.querySelector('code').innerText;
                    navigator.clipboard.writeText(code).then(() => {
                        const copyText = button.querySelector('.copy-text');
                        button.classList.add('copied');
                        copyText.textContent = 'Copied!';
                        setTimeout(() => {
                            button.classList.remove('copied');
                            copyText.textContent = 'Copy';
                        }, 2000);
                    });
                });
            });
        }

        function updateSlider() {
            document.querySelectorAll('.slide').forEach((el, i) => {
                el.classList.toggle('active', i === currentSlide);
            });
            slideCounter.textContent = `${currentSlide + 1} / ${slides.length}`;
            prevBtn.disabled = currentSlide === 0;
            nextBtn.disabled = currentSlide === slides.length - 1;
            progressBar.style.width = `${((currentSlide + 1) / slides.length) * 100}%`;
            Prism.highlightAll();
        }
        
        function initSlider() {
             slides.forEach((slideData, index) => {
                sliderContainer.appendChild(createSlide(slideData, index));
             });
            updateSlider();
            addCopyFunctionality();
        }

        prevBtn.addEventListener('click', () => {
            if (currentSlide > 0) {
                currentSlide--;
                updateSlider();
            }
        });

        nextBtn.addEventListener('click', () => {
            if (currentSlide < slides.length - 1) {
                currentSlide++;
                updateSlider();
            }
        });
        
        initSlider();
    </script>
</body>
</html>

