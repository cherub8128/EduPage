<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>범용 JS/AI 게임 제작 가이드 (v3.6)</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+KR:wght@400;500;700&display=swap" rel="stylesheet">
    <style>
        body { font-family: 'Noto Sans KR', sans-serif; }
        .step { scroll-margin-top: 80px; }
        .prompt-block, .code-block-provided { position: relative; }
        .copy-button { position: absolute; top: 0.8rem; right: 0.8rem; background-color: #4A5568; color: white; padding: 0.25rem 0.6rem; border-radius: 0.375rem; font-size: 0.8rem; cursor: pointer; transition: background-color 0.2s; }
        .copy-button:hover { background-color: #2D3748; }
        .copy-button.copied { background-color: #2F855A; }
        .user-input { background-color: #FEF3C7; border: 1px dashed #FBBF24; padding: 1rem; border-radius: 0.5rem; margin-bottom: 1rem; }
        .workflow-guide { background-color: #E6FFFA; border: 1px solid #38B2AC; padding: 1.5rem; border-radius: 0.5rem; margin-top: 1.5rem; }
        .config-guide { background-color: #FFFBEB; border: 1px solid #F6E05E; padding: 1.5rem; border-radius: 0.5rem; margin-top: 1.5rem; }
        .modal-card { transition: transform 0.2s, box-shadow 0.2s; }
        .modal-card:hover { transform: translateY(-4px); box-shadow: 0 10px 15px -3px rgb(0 0 0 / 0.1), 0 4px 6px -4px rgb(0 0 0 / 0.1); }
        .tab-button { padding: 0.5rem 1rem; cursor: pointer; border-bottom: 2px solid transparent; transition: all 0.2s; color: #4A5568; }
        .tab-button.active { border-color: #F59E0B; color: #1E293B; font-weight: 600; }
        .tab-content { display: none; }
        .tab-content.active { display: block; }
    </style>
</head>
<body class="bg-slate-50 text-slate-800">

    <div id="theme-modal" class="fixed inset-0 bg-black bg-opacity-60 flex items-center justify-center p-4 z-50 hidden">
        <div class="bg-white rounded-2xl shadow-2xl w-full max-w-4xl max-h-[90vh] flex flex-col">
            <div class="p-5 border-b flex justify-between items-center sticky top-0 bg-white rounded-t-2xl">
                <h2 class="text-xl font-bold text-slate-800">추천 게임 주제</h2>
                <button id="close-modal-btn" class="text-3xl font-light text-slate-500 hover:text-slate-800">&times;</button>
            </div>
            <div id="theme-grid" class="p-6 grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-5 overflow-y-auto"></div>
        </div>
    </div>

    <div class="container mx-auto p-4 sm:p-6 md:p-8 max-w-4xl">
        <header class="text-center my-8 md:my-12">
            <h1 class="text-3xl sm:text-4xl md:text-5xl font-bold text-slate-900">범용 JS/AI 게임 제작 가이드 (v3.6)</h1>
            <p class="mt-4 text-base sm:text-lg text-slate-600">초보자부터 전문가까지, 자신만의 AI 게임을 만들 수 있는 최종 워크플로우</p>
        </header>
        
        <section class="step bg-white p-6 sm:p-8 rounded-2xl shadow-lg border border-slate-200 mb-10">
            <h2 class="text-2xl font-bold mb-4 border-b pb-3 text-slate-900">전체 프로세스 개요</h2>
            <ol class="list-decimal list-inside space-y-3 text-slate-700">
                <li><strong class="font-semibold text-slate-800">게임 아이디어 구체화:</strong> 만들고 싶은 게임의 상세 기획안 작성</li>
                <li><strong class="font-semibold text-slate-800">통합 AI 웹 게임 제작:</strong> AI 학습과 플레이가 모두 가능한 JS 게임 로직 개발</li>
                <li><strong class="font-semibold text-slate-800">Python WebSocket 환경 설정:</strong> JS 게임을 제어하는 Gymnasium 호환 RL 환경 설정</li>
                <li><strong class="font-semibold text-slate-800">AI 모델 학습 및 변환:</strong> 게임 종류에 맞는 방식으로 AI 모델을 학습하고 ONNX 파일로 자동 변환</li>
                <li><strong class="font-semibold text-slate-800">최종 AI 게임 테스트:</strong> 로컬 서버로 완성된 게임 테스트</li>
                <li><strong class="font-semibold text-slate-800">GitHub Pages 배포:</strong> 완성된 AI 웹 게임을 전 세계에 무료로 배포</li>
            </ol>
        </section>

        <section id="step1" class="step bg-white p-6 sm:p-8 rounded-2xl shadow-lg border border-slate-200 mb-10">
            <h2 class="text-2xl font-bold mb-4 border-b pb-3 text-slate-900">단계 1: 게임 아이디어 구체화하기</h2>
            <p class="mb-4 text-slate-700">'추천 주제 보기' 버튼을 눌러 영감을 얻고, 상세 기획안을 요청하는 프롬프트를 복사하세요.</p>
            <button id="open-modal-btn" class="mb-6 bg-amber-500 text-white font-bold py-2 px-4 rounded-lg hover:bg-amber-600 transition-colors">🎮 추천 주제 보기 & 영감 얻기</button>
            <div class="prompt-block">
                <button class="copy-button">복사</button>
                <pre class="bg-slate-100 text-slate-800 p-4 rounded-lg overflow-x-auto text-sm"><code id="step1-prompt-code" class="language-text">You are a creative game designer. Based on the theme "[여기에 선택한 게임 주제와 간단한 설명을 입력하세요.]", please develop a detailed and engaging game plan with these four sections: Game Concept, Player Objective, Controls, Win/Loss Conditions. Write in Korean.</code></pre>
            </div>
        </section>

        <section id="step2" class="step bg-white p-6 sm:p-8 rounded-2xl shadow-lg border border-slate-200 mb-10">
            <h2 class="text-2xl font-bold mb-4 border-b pb-3 text-slate-900">단계 2: 통합 AI 웹 게임 제작</h2>
            <div class="user-input mb-6">
                <h3 class="font-semibold text-lg text-slate-800 mb-2">파일 생성 안내</h3>
                <ol class="list-decimal list-inside space-y-2 text-sm text-slate-700">
                    <li>프로젝트 폴더(예: `my-ai-game`)를 만들고 코드 에디터로 엽니다.</li>
                    <li>폴더 안에 `index.html`이라는 빈 파일을 생성합니다.</li>
                    <li>아래 탭에서 원하는 작업을 선택하고 프롬프트를 복사하여 AI에게 요청한 뒤, 생성된 전체 코드를 `index.html` 파일에 붙여넣으세요.</li>
                </ol>
            </div>
            <div class="border-b border-slate-200"><nav class="flex -mb-px" aria-label="Tabs">
                <button class="tab-button active" data-tab="new-game">새 게임 생성</button>
                <button class="tab-button" data-tab="modify-game">기존 게임 수정</button>
            </nav></div>

            <div id="tab-new-game" class="tab-content active mt-6">
                <div class="prompt-block">
                    <button class="copy-button">복사</button>
                    <pre class="bg-slate-100 text-slate-800 p-4 rounded-lg overflow-x-auto text-sm"><code id="step2-new-game-prompt" class="language-text">You are an elite game developer, a master of Matter.js, and an expert in creating robust, AI-ready web games. Your task is to write the complete code for a single, self-contained `index.html` file based on the provided game plan.

**Game Logic Plan:**

[여기에 1단계에서 생성된 게임 기획안을 붙여넣으세요.]

**CRITICAL JavaScript Implementation Requirements:**

1.  **Game Modes & State:** Must support `USER`, `AI`, `TRAINING` modes. Use `sessionStorage` to remember the current mode after a refresh, automatically re-entering `TRAINING` mode if it was active.

2.  **Reinforcement Learning Deadlock Prevention:**
    * In `USER` and `AI` modes, the Matter.js `Runner` must be enabled (`runner.enabled = true`) for smooth, real-time gameplay.
    * **Crucially, upon entering `TRAINING` mode, the automatic `Runner` MUST be disabled (`runner.enabled = false`).**
    * In `TRAINING` mode, the physics simulation must only advance a single step via a manual call to `Engine.update(engine, 1000 / 60)` from within the `stepGameForTraining` function. This gives the Python RL agent absolute control over the game loop and prevents race conditions or deadlocks.

3.  **WebSocket Interface & RL Protocol:**
    * Implement `connectWebSocket()` to connect to `ws://localhost:8765`.
    * The interface must handle a `reset` command (which triggers `resetForTraining`) and an `action` command (which triggers `stepGameForTraining`).
    * The `stepGameForTraining(action)` function must be designed to accept a **continuous floating-point value** (e.g., from -1.0 to 1.0) and translate that into a proportionally scaled force or velocity within the game.
    * **Strict RL Protocol:**
        * The `resetForTraining()` function must ONLY send back the initial observation packet: `{observation: getObservation()}`.
        * The `stepGameForTraining(action)` function must send the complete data packet: `{observation, reward, done}`.

4.  **Robust Physics & World Design:**
    * Use Matter.js collision categories to prevent unintended physical interactions.
    * Game resets must be stable. Use a state flag (e.g., `isRoundOver`) to prevent multiple simultaneous resets.
    * The game world (e.g., the ground or play area) must be significantly larger than the visible screen area.
    * The game viewport must smoothly track the primary player-controlled object to allow for unrestricted movement.

5.  **Core RL Functions & State Management:**
    * Implement the core functions: `getObservation()`, `resetForTraining()`, and `stepGameForTraining(action)`.
    * **Meaningful Resets:** The `resetGame()` function must always initialize the environment in a **non-trivial, randomized state** that requires immediate and skillful action from the player or agent. Avoid starting in a perfectly stable "solved" state.
    * **High-Throughput Training:** In `TRAINING` mode, reaching a terminal state (`done: true`) must trigger an **immediate** call to `resetForTraining()` to maximize training speed, bypassing any delays used for visual effect in other modes.

// --- For 2-Player / Self-Play Games ONLY ---
/*
6.  **Dual ONNX Model Support:**
    * The game must load `model.onnx` and `opponent.onnx`. Use a cache-busting query (`?v=` + Date.now()) when loading `opponent.onnx`.
    * In `TRAINING` mode, the opponent character must be controlled by the `opponent.onnx` model. Decouple the AI's async decision-making from the synchronous physics loop (e.g., using `setInterval` for decisions and applying the latest decision in the main loop).
*/
</code></pre>
                </div>
            </div>
            <div id="tab-modify-game" class="tab-content mt-6">
                 <div class="prompt-block">
                    <button class="copy-button">복사</button>
                    <pre class="bg-slate-100 text-slate-800 p-4 rounded-lg overflow-x-auto text-sm"><code id="step2-modify-game-prompt" class="language-text">You are an expert reinforcement learning engineer. Your task is to modify the provided HTML game code to make it compatible with a Python-based training environment. You MUST inject the following features without breaking the original game's functionality.

You are an expert AI integration specialist and a master of JavaScript game engineering. Your task is to intelligently modify an existing single-file HTML game to make it a robust environment for reinforcement learning. You must analyze the provided game code and inject the necessary logic without breaking the original gameplay.

**CRITICAL Integration Requirements:**

1.  **Inject Game Modes & State Management:**
    * Introduce UI elements (e.g., a modal on startup) and the underlying logic to switch between three distinct modes: `USER` (original human play), `AI` (inference with a model), and `TRAINING` (for the RL agent).
    * Use `sessionStorage` to persist the current mode across page refreshes, automatically re-entering `TRAINING` mode if it was the last active state.

2.  **Implement Reinforcement Learning Deadlock Prevention:**
    * Analyze the game's main loop (e.g., `requestAnimationFrame`, `setInterval`, or a physics engine's `Runner`).
    * In `USER` and `AI` modes, this main loop must run in real-time as originally intended.
    * **Crucially, upon entering `TRAINING` mode, the game's automatic, real-time loop MUST be stopped or disabled.**
    * The game's state should only advance when a manual `step` command is received from the training agent.

3.  **Inject WebSocket Interface & Strict RL Protocol:**
    * Implement a `connectWebSocket()` function to establish a connection with the Python training server at `ws://localhost:8765`.
    * The WebSocket listener must correctly handle two primary commands from the server: `reset` (which triggers the `resetForTraining` function) and `action` (which triggers the `stepGameForTraining` function).
    * **Adhere to the standard RL communication protocol:**
        * The `resetForTraining()` function's ONLY responsibility is to reset the environment and send back the initial observation packet: `{observation: getObservation()}`.
        * The `stepGameForTraining(action)` function must execute the action, advance the game state by a single discrete step (e.g., one physics tick or one frame), and then send back the complete data packet: `{observation: getObservation(), reward: calculatedReward, done: isDone}`.

4.  **Create and Adapt Core RL Functions:**
    * Analyze the existing game variables to create a `getObservation()` function that returns a meaningful, numeric state representation (e.g., positions, velocities, angles) as an array.
    * Create a `stepGameForTraining(action)` function. This function must:
        a.  Accept an `action` (ideally a continuous floating-point value for versatility).
        b.  Translate this action into a force, velocity, or other control input in the game.
        c.  Manually advance the game simulation by exactly one tick/frame.
        d.  Calculate the `reward` and the `done` status based on the new game state.
        e.  Send the complete data packet back via WebSocket.
    * Create a `resetForTraining()` function that resets the game to a **non-trivial, randomized starting state** to ensure effective learning.
    * **High-Throughput Training:** In `TRAINING` mode, when a `done` state is reached, the environment must trigger an **immediate** reset to maximize training episodes, bypassing any animations or delays used in other modes.

5.  **Inject ONNX Model Support (for AI Mode):**
    * Add the necessary scripts (e.g., `onnxruntime-web`) to load an ONNX model.
    * Implement logic to load `model.onnx`.
    * In `AI` mode, the game loop should continuously:
        a.  Get the current observation using `getObservation()`.
        b.  Feed the observation into the loaded ONNX model to get an action.
        c.  Apply the action to control the player character.

// --- For 2-Player / Self-Play Games ONLY ---
/*
6.  **Inject Dual ONNX Support:**
    * In addition to `model.onnx`, load an `opponent.onnx` model. Use a cache-busting query string (e.g., `?v=${Date.now()}`) when fetching `opponent.onnx` to ensure the latest version is always loaded during self-play training.
    * In `TRAINING` mode, the opponent entity must be controlled by the `opponent.onnx` model.
*/

**Original Game Code:**

[여기에 사용자의 기존 게임 코드를 붙여넣으세요.]
</code></pre>
                </div>
            </div>
        </section>

        <section id="step3" class="step bg-white p-6 sm:p-8 rounded-2xl shadow-lg border border-slate-200 mb-10">
            <h2 class="text-2xl font-bold mb-4 border-b pb-3 text-slate-900">단계 3: Python WebSocket 강화학습 환경 설정</h2>
            <div class="user-input mb-6">
                <h3 class="font-semibold text-lg text-slate-800 mb-2">파일 생성 및 라이브러리 설치</h3>
                <ol class="list-decimal list-inside space-y-2 text-sm text-slate-700">
                    <li>프로젝트 폴더에 `websocket_env.py` 파일을 생성하고 아래 코드를 붙여넣습니다.</li>
                    <li>터미널을 열고 `pip install gymnasium numpy websockets` 명령어로 라이브러리를 설치합니다.</li>
                </ol>
            </div>
             <div class="code-block-provided">
                <button class="copy-button">복사</button>
                <pre class="bg-slate-100 text-slate-800 p-4 rounded-lg overflow-x-auto text-sm"><code class="language-python">import gymnasium as gym
from gymnasium import spaces
import numpy as np
import asyncio
import websockets
import json
import logging
import threading
import queue

# Websockets 라이브러리의 상세 로그 비활성화
logging.getLogger("websockets").setLevel(logging.ERROR)
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')

class ServerThread(threading.Thread):
    """
    백그라운드에서 웹소켓 서버를 실행하고 메인 스레드와 큐를 통해 통신하는
    독립적인 스레드입니다.
    """
    def __init__(self):
        super().__init__()
        self.loop = asyncio.new_event_loop()
        self.command_queue = queue.Queue()
        self.observation_queue = queue.Queue()
        self.daemon = True # 메인 스레드가 종료되면 함께 종료

    async def handler(self, websocket, path):
        logging.info(f"새로운 클라이언트 연결됨: {websocket.remote_address}")
        consumer_task = asyncio.ensure_future(self.consumer(websocket))
        producer_task = asyncio.ensure_future(self.producer(websocket))
        done, pending = await asyncio.wait([consumer_task, producer_task], return_when=asyncio.FIRST_COMPLETED)
        for task in pending: task.cancel()
        logging.info(f"클라이언트 연결 종료: {websocket.remote_address}")

    async def consumer(self, websocket):
        """메인 스레드로부터 명령을 받아 클라이언트로 전송"""
        while True:
            try:
                command = await self.loop.run_in_executor(None, self.command_queue.get)
                await websocket.send(json.dumps(command))
            except websockets.exceptions.ConnectionClosed: break

    async def producer(self, websocket):
        """클라이언트로부터 관측 데이터를 받아 메인 스레드로 전송"""
        while True:
            try:
                message = await websocket.recv()
                data = json.loads(message)
                # BUG FIX: CartPole의 reset 로직은 observation만 보내므로, reward/done이 없어도 처리
                if "observation" in data:
                    obs = np.array(data["observation"], dtype=np.float32)
                    reward = data.get("reward", 0) # reward가 없으면 0으로 처리
                    done = data.get("done", False) # done이 없으면 False로 처리
                    self.observation_queue.put((obs, reward, done))
            except websockets.exceptions.ConnectionClosed: break

    def run(self):
        asyncio.set_event_loop(self.loop)
        start_server = websockets.serve(self.handler, "localhost", 8765)
        self.loop.run_until_complete(start_server)
        logging.info("웹소켓 서버가 8765 포트에서 시작되었습니다.")
        self.loop.run_forever()

    def stop(self):
        if self.loop.is_running(): self.loop.call_soon_threadsafe(self.loop.stop)

class WebSocketEnv(gym.Env):
    def __init__(self, observation_shape, action_space_config):
        super(WebSocketEnv, self).__init__()
        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=observation_shape, dtype=np.float32)
        if action_space_config['type'] == 'discrete': self.action_space = spaces.Discrete(action_space_config['n'])
        elif action_space_config['type'] == 'continuous': self.action_space = spaces.Box(low=np.array(action_space_config['low']), high=np.array(action_space_config['high']), dtype=np.float32)
        self.server_thread = ServerThread()
        self.server_thread.start()
        print("첫 클라이언트의 연결 및 데이터 수신을 기다립니다...")

    def reset(self, seed=None, options=None):
        super().reset(seed=seed)
        
        # --- BUG FIX: 큐를 비워 이전 세션의 '유령 데이터'를 제거합니다 ---
        with self.server_thread.observation_queue.mutex:
            self.server_thread.observation_queue.queue.clear()
            
        self.server_thread.command_queue.put({"command": "reset"})
        obs, _, _ = self.server_thread.observation_queue.get() # 블로킹 호출로 새 데이터를 기다림
        
        # print("환경 리셋 완료. 다음 세대 학습을 시작합니다.")
        return obs, {}

    def step(self, action):
        action_to_send = action.tolist() if isinstance(action, np.ndarray) else float(action) # 연속 행동은 float
        self.server_thread.command_queue.put({"command": "action", "action": action_to_send})
        obs, reward, done = self.server_thread.observation_queue.get() # 블로킹 호출
        return obs, reward, done, False, {}

    def render(self, mode='human'): pass
    
    def close(self):
        self.server_thread.stop()
        print("웹소켓 서버가 종료되었습니다.")
</code></pre>
            </div>
        </section>
        
        <section id="step4" class="step bg-white p-6 sm:p-8 rounded-2xl shadow-lg border border-slate-200 mb-10">
            <h2 class="text-2xl font-bold mb-4 border-b pb-3 text-slate-900">단계 4: AI 모델 학습 및 ONNX 변환</h2>
            <div class="user-input mb-6">
                <h3 class="font-semibold text-lg text-slate-800 mb-2">파일 생성 및 라이브러리 설치</h3>
                <ol class="list-decimal list-inside space-y-2 text-sm text-slate-700">
                    <li>아래 탭에서 자신의 게임 종류에 맞는 스크립트 코드를 복사하고 프로젝트 폴더에 파일로 저장합니다.</li>
                    <li>터미널에서 `pip install stable-baselines3[extra] torch onnx onnxruntime tensorboard` 명령어로 라이브러리를 설치합니다.</li>
                </ol>
            </div>
            <div class="border-b border-slate-200"><nav class="flex -mb-px" aria-label="Tabs">
                <button class="tab-button active" data-tab="simple">기본 학습 (1인용)</button>
                <button class="tab-button" data-tab="selfplay">셀프 플레이 학습 (2인용)</button>
            </nav></div>
            <div id="tab-simple" class="tab-content active mt-6">
                <div class="code-block-provided">
                    <button class="copy-button">복사</button>
                    <pre class="bg-slate-100 text-slate-800 p-4 rounded-lg overflow-x-auto text-sm"><code class="language-python"># train_simple.py
import os, time, torch, webbrowser, threading
import http.server, socketserver
from stable_baselines3 import PPO
from stable_baselines3.common.callbacks import CheckpointCallback, ProgressBarCallback, CallbackList
from stable_baselines3.common.logger import configure
from websocket_env import WebSocketEnv

# --- 중요 설정 ---
# 1. 관찰 공간 (Observation Space) - AI의 '눈'
OBSERVATION_SHAPE = (4,)
# OBSERVATION_SHAPE = (1, 84, 84) # CnnPolicy를 위한 이미지 관찰 예시
# 2. 행동 공간 (Action Space) - AI의 '손'
ACTION_SPACE_CONFIG = {'type': 'discrete', 'n': 5}
# ACTION_SPACE_CONFIG = {'type': 'continuous', 'low': [-2.0], 'high': [2.0]} # 1차원 연속 행동 예시
# ACTION_SPACE_CONFIG = {'type': 'continuous', 'low': [-1.0, -3.0], 'high': [1.0, 3.0]} # 2차원 연속 행동 예시

# -----------------
LOG_DIR, TOTAL_TIMESTEPS, PORT = "training_logs", 1_000_000, 8000
os.makedirs(LOG_DIR, exist_ok=True)

class WebServerThread(threading.Thread):
    def __init__(self, port): super().__init__(); self.port, self.server, self.daemon = port, None, True
    def run(self): self.server = socketserver.TCPServer(("", self.port), http.server.SimpleHTTPRequestHandler); self.server.serve_forever()
    def stop(self):
        if self.server: self.server.shutdown()

class OnnxablePolicy(torch.nn.Module):
    def __init__(self, policy): super().__init__(); self.policy = policy
    def forward(self, observation):
        action, _ = self.policy.predict(observation.cpu().numpy(), deterministic=True)
        return torch.from_numpy(action).to(observation.device)

def export_to_onnx(model_path, onnx_path):
    print(f"\n모델 {model_path}를 ONNX 형식({onnx_path})으로 변환합니다...")
    model = PPO.load(model_path, device='cpu')
    onnxable_model = OnnxablePolicy(model.policy)
    dummy_input = torch.randn(1, *OBSERVATION_SHAPE)
    torch.onnx.export(onnxable_model, dummy_input, onnx_path, opset_version=12, input_names=["observation"], output_names=["action"])
    print("ONNX 변환 완료.")

def find_latest_run_and_checkpoint():
    if not os.path.isdir(LOG_DIR): return None, None
    runs = sorted([d for d in os.listdir(LOG_DIR) if os.path.isdir(os.path.join(LOG_DIR, d))], reverse=True)
    for run in runs:
        run_path = os.path.join(LOG_DIR, run)
        checkpoints_path = os.path.join(run_path, "checkpoints")
        if not os.path.isdir(checkpoints_path): continue
        checkpoints = [f for f in os.listdir(checkpoints_path) if f.startswith("rl_model_") and f.endswith(".zip")]
        if checkpoints:
            latest_checkpoint = max(checkpoints, key=lambda f: int(f.split("_")[2].replace(".zip", "")))
            return run, os.path.join(checkpoints_path, latest_checkpoint)
    return None, None

def main():
    web_server = WebServerThread(PORT)
    web_server.start()
    time.sleep(1)
    webbrowser.open(f'http://localhost:{PORT}')
    
    latest_run_name, latest_checkpoint = find_latest_run_and_checkpoint()
    
    TENSORBOARD_LOG_NAME = latest_run_name if latest_run_name else f"PPO_{int(time.time())}"
    run_path = os.path.join(LOG_DIR, TENSORBOARD_LOG_NAME)
    
    checkpoint_path = os.path.join(run_path, "checkpoints")
    os.makedirs(checkpoint_path, exist_ok=True)
    
    env = WebSocketEnv(observation_shape=OBSERVATION_SHAPE, action_space_config=ACTION_SPACE_CONFIG)
    custom_logger = configure(run_path, ["stdout", "tensorboard"])
    
    checkpoint_callback = CheckpointCallback(save_freq=20000, save_path=checkpoint_path, name_prefix="rl_model")
    progress_callback = ProgressBarCallback()
    callback_list = CallbackList([checkpoint_callback, progress_callback])
    
    policy_type = "CnnPolicy" if len(OBSERVATION_SHAPE) == 3 else "MlpPolicy"
    
    if latest_checkpoint:
        print(f"체크포인트에서 학습을 재개합니다: {latest_checkpoint}")
        model = PPO.load(latest_checkpoint, env=env, device='auto')
    else:
        print(f"{policy_type} 정책으로 새로운 학습 세션을 시작합니다.")
        model = PPO(policy_type, env, verbose=0, device='auto') # verbose=0 for clean progress bar
        
    model.set_logger(custom_logger)
    final_model_path = ""
    try:
        model.learn(total_timesteps=TOTAL_TIMESTEPS, callback=callback_list, reset_num_timesteps=not bool(latest_checkpoint))
        final_model_path = os.path.join(run_path, "final_model.zip")
        model.save(final_model_path)
        print(f"\n최종 모델 저장 완료: {final_model_path}")
    finally:
        env.close()
        web_server.stop()

    if os.path.exists(final_model_path):
        export_to_onnx(final_model_path, "model.onnx")

if __name__ == '__main__':
    main()
</code></pre>
                </div>
            </div>

            <div id="tab-selfplay" class="tab-content mt-6">
                 <div class="code-block-provided">
                    <button class="copy-button">복사</button>
                    <pre class="bg-slate-100 text-slate-800 p-4 rounded-lg overflow-x-auto text-sm"><code class="language-python"># train_selfplay.py
import os, time, torch, webbrowser, threading
import http.server, socketserver
from stable_baselines3 import PPO
from stable_baselines3.common.callbacks import CheckpointCallback, ProgressBarCallback, CallbackList
from stable_baselines3.common.logger import configure
from websocket_env import WebSocketEnv

# --- 중요 설정 ---
# 1. 관찰 공간 (Observation Space) - AI의 '눈'
OBSERVATION_SHAPE = (8,)
# OBSERVATION_SHAPE = (1, 84, 84) # CnnPolicy를 위한 이미지 관찰 예시
# 2. 행동 공간 (Action Space) - AI의 '손'
ACTION_SPACE_CONFIG = {'type': 'discrete', 'n': 5}
# ACTION_SPACE_CONFIG = {'type': 'continuous', 'low': [-2.0], 'high': [2.0]} # 1차원 연속 행동 예시
# ACTION_SPACE_CONFIG = {'type': 'continuous', 'low': [-1.0, -3.0], 'high': [1.0, 3.0]} # 2차원 연속 행동 예시
# -----------------
TOTAL_TRAINING_STEPS, STEPS_PER_ITERATION = 1_000_000, 50_000
MODEL_DIR, LOG_DIR, PORT = "models", "training_logs", 8000
os.makedirs(MODEL_DIR, exist_ok=True)
os.makedirs(LOG_DIR, exist_ok=True)

class WebServerThread(threading.Thread):
    def __init__(self, port): super().__init__(); self.port, self.server, self.daemon = port, None, True
    def run(self): self.server = socketserver.TCPServer(("", self.port), http.server.SimpleHTTPRequestHandler); self.server.serve_forever()
    def stop(self):
        if self.server: self.server.shutdown()

class OnnxablePolicy(torch.nn.Module):
    def __init__(self, policy): super().__init__(); self.policy = policy
    def forward(self, observation):
        action, _ = self.policy.predict(observation.cpu().numpy(), deterministic=True)
        return torch.from_numpy(action).to(observation.device)

def export_to_onnx(model_path, onnx_path):
    print(f"\n모델 {model_path}를 ONNX 형식({onnx_path})으로 변환합니다...")
    model = PPO.load(model_path, device='cpu')
    onnxable_model = OnnxablePolicy(model.policy)
    dummy_input = torch.randn(1, *OBSERVATION_SHAPE)
    torch.onnx.export(onnxable_model, dummy_input, onnx_path, opset_version=12, input_names=["observation"], output_names=["action"])
    print("ONNX 변환 완료.")

def find_latest_log_dir():
    if not os.path.isdir(LOG_DIR): return None
    runs = [d for d in os.listdir(LOG_DIR) if os.path.isdir(os.path.join(LOG_DIR, d)) and d.startswith("PPO_SelfPlay")]
    if not runs: return None
    # 시간순으로 가장 최신 폴더 찾기
    latest_run = max(runs, key=lambda d: os.path.getmtime(os.path.join(LOG_DIR, d)))
    return latest_run

def main():
    web_server = WebServerThread(PORT)
    web_server.start()
    time.sleep(1)
    webbrowser.open(f'http://localhost:{PORT}')
    
    env = WebSocketEnv(observation_shape=OBSERVATION_SHAPE, action_space_config=ACTION_SPACE_CONFIG)
    
    latest_model_path = os.path.join(MODEL_DIR, "latest_model.zip")
    
    # TensorBoard 로깅 연속성을 위한 로그 디렉토리 설정
    latest_run_name = find_latest_log_dir()
    TENSORBOARD_LOG_NAME = latest_run_name if os.path.exists(latest_model_path) and latest_run_name else f"PPO_SelfPlay_{int(time.time())}"
    run_path = os.path.join(LOG_DIR, TENSORBOARD_LOG_NAME)
    
    custom_logger = configure(run_path, ["stdout", "tensorboard"])
    
    # 체크포인트와 프로그레스 바를 위한 콜백 리스트 설정
    checkpoint_path = os.path.join(run_path, "checkpoints")
    os.makedirs(checkpoint_path, exist_ok=True)
    checkpoint_callback = CheckpointCallback(save_freq=20000, save_path=checkpoint_path, name_prefix="rl_model")
    callback_list = CallbackList([checkpoint_callback, ProgressBarCallback()])
    
    policy_type = "CnnPolicy" if len(OBSERVATION_SHAPE) == 3 else "MlpPolicy"

    if os.path.exists(latest_model_path):
        print(f"저장된 모델 {latest_model_path}에서 학습을 재개합니다.")
        model = PPO.load(latest_model_path, env=env, device='auto') 
    else:
        print(f"{policy_type} 정책으로 새로운 학습을 시작합니다.")
        model = PPO(policy_type, env, verbose=0, device='auto')
        
    model.set_logger(custom_logger)
    
    if not os.path.exists("opponent.onnx"):
        print("'opponent.onnx' 파일이 없어 현재 에이전트로 초기 상대를 생성합니다.")
        model.save(os.path.join(MODEL_DIR, "initial_model.zip"))
        export_to_onnx(os.path.join(MODEL_DIR, "initial_model.zip"), "opponent.onnx")
    else:
        print("기존 'opponent.onnx' 파일을 초기 상대로 사용합니다.")
    
    try:
        total_steps_done = model.num_timesteps
        while total_steps_done < TOTAL_TRAINING_STEPS:
            model.learn(total_timesteps=total_steps_done + STEPS_PER_ITERATION, callback=callback_list, reset_num_timesteps=False)
            total_steps_done = model.num_timesteps
            model.save(latest_model_path)
            export_to_onnx(latest_model_path, "opponent.onnx")
            if total_steps_done < TOTAL_TRAINING_STEPS:
                input(f"--- CHECKPOINT ({total_steps_done}/{TOTAL_TRAINING_STEPS} steps) ---\n"
                      f">>> 상대방 모델이 업데이트되었습니다. 브라우저를 새로고침(F5)한 뒤, 여기서 Enter를 누르세요...")
    finally:
        env.close()
        web_server.stop()
    
    export_to_onnx(latest_model_path, "model.onnx")

if __name__ == '__main__':
    main()
</code></pre>
                </div>
            </div>
            <div class="config-guide">
                <h4 class="text-lg font-bold">AI 설정 가이드</h4>
                <div class="mt-4">
                    <h5 class="font-semibold">관찰 공간(Observation Space) - AI의 '눈'</h5>
                    <ul class="list-disc pl-5 mt-2 space-y-2 text-sm">
                        <li><strong>벡터 관찰:</strong> `(숫자,)` 형태 (예: `(8,)`). AI는 `[좌표, 속도]` 등 숫자 리스트로 상태를 인식합니다. 이때 SB3는 자동으로 **MlpPolicy**를 사용합니다.</li>
                        <li><strong>이미지 관찰:</strong> `(채널, 높이, 너비)` 형태 (예: `(1, 84, 84)`). AI는 게임 화면 픽셀 자체를 보고 학습합니다. 이때 SB3는 자동으로 **CnnPolicy**를 사용합니다.</li>
                    </ul>
                </div>
                <div class="mt-4">
                    <h5 class="font-semibold">행동 공간(Action Space) - AI의 '손'</h5>
                    <ul class="list-disc pl-5 mt-2 space-y-2 text-sm">
                        <li><strong>이산(Discrete) 행동:</strong> "점프", "왼쪽" 같이 버튼처럼 딱딱 끊어지는 행동입니다. JS의 `applyAction`은 정수(`0, 1, 2...`)를 받습니다.</li>
                        <li><strong>연속(Continuous) 행동:</strong> 로켓 추진력(-1.0 ~ 1.0)처럼 세밀하고 연속적인 값으로 조작합니다. JS의 `applyAction`은 숫자 배열(`[-0.5, 0.88]`)을 받습니다.</li>
                    </ul>
                </div>
            </div>
        </section>

        <section id="step5" class="step bg-white p-6 sm:p-8 rounded-2xl shadow-lg border border-slate-200 mb-10">
            <h2 class="text-2xl font-bold mb-4 border-b pb-3 text-slate-900">단계 5: 최종 AI 게임 테스트</h2>
             <div class="workflow-guide">
                <h4 class="text-lg">AI 플레이 감상하기</h4>
                <p class="mt-2 text-sm text-slate-700">이제 모든 준비가 끝났습니다. 학습의 최종 결과물인 `model.onnx`가 얼마나 똑똑해졌는지 확인해볼 시간입니다.</p>
                <ol class="list-decimal list-inside space-y-2 text-sm text-slate-700 mt-3">
                    <li>프로젝트 폴더에서 터미널을 열고 <code>python -m http.server</code> 명령어로 로컬 서버를 실행합니다.</li>
                     <li>웹 브라우저에서 <a href="http://localhost:8000" target="_blank" class="text-teal-600 underline">http://localhost:8000</a> 으로 접속합니다.</li>
                     <li>게임이 로드되면, **'AI 모드'** 버튼을 클릭하여 학습된 모델의 플레이를 감상하세요!</li>
                </ol>
            </div>
        </section>

        <section id="step6" class="step bg-white p-6 sm:p-8 rounded-2xl shadow-lg border border-slate-200 mb-10">
            <h2 class="text-2xl font-bold mb-4 border-b pb-3 text-slate-900">단계 6: GitHub Pages 배포</h2>
            <p class="mb-6 text-slate-700">최종 단계입니다. 완성된 프로젝트를 VS Code에서 바로 GitHub에 올리고, GitHub Pages를 통해 전 세계에 배포합니다.</p>
            <div class="space-y-6 text-slate-700">
                <div>
                    <h3 class="font-semibold text-lg text-slate-800">1. 사전 준비: Git 설치 및 설정</h3>
                    <p class="mt-1 ml-2">Git이 설치되어 있지 않다면 <a href="https://git-scm.com/" target="_blank" class="text-teal-600 underline">git-scm.com</a>에서 다운로드하여 설치합니다. 설치 후, 터미널을 열어 아래 명령어를 입력하여 사용자 정보를 설정합니다 (최초 한 번만 필요).</p>
                    <pre class="bg-slate-100 text-slate-800 p-2 mt-1 rounded-md text-sm"><code>git config --global user.name "Your Name"
git config --global user.email "you@example.com"</code></pre>
                </div>
                <div>
                    <h3 class="font-semibold text-lg text-slate-800">2. VS Code에서 GitHub 계정 연동</h3>
                    <p class="mt-1 ml-2">VS Code 왼쪽 하단의 사람 모양 아이콘(계정)을 클릭하고, 'GitHub으로 로그인(Sign in with GitHub)'을 선택하여 브라우저의 안내에 따라 계정을 연동합니다.</p>
                </div>
                <div>
                    <h3 class="font-semibold text-lg text-slate-800">3. Git 저장소 초기화 및 첫 커밋</h3>
                    <p class="mt-1 ml-2">VS Code 왼쪽의 '소스 제어' 탭(가지 모양 아이콘)으로 이동하여 '리포지토리 초기화(Initialize Repository)' 버튼을 클릭합니다. 그 후, 상단의 메시지 입력란에 "Initial commit"과 같은 첫 커밋 메시지를 작성한 후 ✓ 커밋 버튼을 눌러 프로젝트 파일(`index.html`, `model.onnx` 등)을 커밋합니다.</p>
                </div>
                <div>
                    <h3 class="font-semibold text-lg text-slate-800">4. GitHub에 게시하기</h3>
                    <p class="mt-1 ml-2">'소스 제어' 탭에 나타나는 'GitHub에 게시(Publish to GitHub)' 버튼을 클릭합니다. VS Code가 GitHub에 저장소를 만드는 과정을 안내합니다. 저장소 이름을 정하고, <strong>반드시 '공개(Public)' 저장소로 설정</strong>해야 GitHub Pages를 무료로 사용할 수 있습니다.</p>
                </div>
                <div>
                    <h3 class="font-semibold text-lg text-slate-800">5. GitHub Pages 활성화</h3>
                    <p class="mt-1 ml-2">게시가 완료되면 GitHub 사이트에서 방금 생성한 저장소로 이동합니다. 'Settings' &rarr; 'Pages' 탭으로 이동하여 'Source'를 'Deploy from a branch'로, 브랜치를 'main' (또는 'master')으로 선택하고 'Save'를 클릭합니다.</p>
                </div>
                <div>
                    <h3 class="font-semibold text-lg text-slate-800">6. 배포 확인 및 공유</h3>
                    <p class="mt-1 ml-2">잠시 후 페이지 상단에 녹색으로 게시 주소(<code class="text-sm">https://&lt;사용자명&gt;.github.io/&lt;저장소명&gt;/</code>)가 나타납니다. 이 주소로 접속하여 게임을 확인하고 전 세계와 공유하세요!</p>
                </div>
            </div>
        </section>

        <section id="step7-download" class="step bg-white p-6 sm:p-8 rounded-2xl shadow-lg border border-slate-200 mb-10">
            <h2 class="text-2xl font-bold mb-4 border-b pb-3 text-slate-900">단계 7: 예제 파일 다운로드 (CartPole)</h2>
            <p class="mb-6 text-slate-700">이 가이드를 통해 최종적으로 완성된 CartPole 게임의 `index.html` 파일입니다. 전체 코드를 직접 확인하고 싶거나, 자신의 프로젝트와 비교하며 참고하고 싶을 때 아래 버튼을 통해 다운로드하세요.</p>
            
            <div class="workflow-guide">
                <h4 class="text-lg">사용 안내</h4>
                <p class="mt-2 text-sm text-slate-700">이 예제 파일을 학습시키려면, 4단계 가이드에서 제공하는 Python 스크립트(`train_simple.py`)의 `OBSERVATION_SHAPE`을 `(4,)`로, `ACTION_SPACE_CONFIG`을 `{'type': 'continuous', 'low': [-2.0], 'high': [2.0]}`으로 수정한 뒤 실행해야 합니다.</p>
            </div>

            <div class="mt-8 text-center">
                <a href="/Reinforcement/Source/CartPole.zip" download="CartPole.zip" 
                class="inline-block bg-teal-500 text-white font-bold py-3 px-6 rounded-lg hover:bg-teal-600 transition-colors no-underline text-base shadow-md hover:shadow-lg transform hover:-translate-y-1">
                    📂 CartPole 예제 다운로드
                </a>
            </div>
        </section>


    </div>

    <script>
        document.addEventListener('DOMContentLoaded', () => {
            const copyButtons = document.querySelectorAll('.copy-button');
            copyButtons.forEach(button => {
                button.addEventListener('click', () => {
                    const code = button.parentElement.querySelector('code').innerText;
                    navigator.clipboard.writeText(code).then(() => {
                        button.textContent = '복사 완료!';
                        button.classList.add('copied');
                        setTimeout(() => { button.textContent = '복사'; button.classList.remove('copied'); }, 2000);
                    });
                });
            });

            const gameLogicTextarea = document.getElementById('game-logic-textarea');
            const step2NewGamePrompt = document.getElementById('step2-new-game-prompt');
            if (gameLogicTextarea && step2NewGamePrompt) {
                const base = step2NewGamePrompt.innerText;
                gameLogicTextarea.addEventListener('input', () => {
                    const userInput = gameLogicTextarea.value;
                    const placeholder = "[여기에 1단계에서 생성된 게임 기획안을 붙여넣으세요.]";
                    step2NewGamePrompt.innerText = userInput.trim() !== '' ? base.replace(placeholder, userInput) : base;
                });
            }

            const existingGameTextarea = document.getElementById('existing-game-textarea');
            const step2ModifyGamePrompt = document.getElementById('step2-modify-game-prompt');
            if (existingGameTextarea && step2ModifyGamePrompt) {
                const base = step2ModifyGamePrompt.innerText;
                existingGameTextarea.addEventListener('input', () => {
                    const userInput = existingGameTextarea.value;
                    const placeholder = "[여기에 사용자의 기존 게임 코드를 붙여넣으세요.]";
                    step2ModifyGamePrompt.innerText = userInput.trim() !== '' ? base.replace(placeholder, userInput) : base;
                });
            }

            const tabButtons = document.querySelectorAll('.tab-button');
            const tabContents = document.querySelectorAll('.tab-content');
            tabButtons.forEach(button => {
                button.addEventListener('click', () => {
                    tabButtons.forEach(btn => btn.classList.remove('active'));
                    button.classList.add('active');
                    const tabId = button.getAttribute('data-tab');
                    tabContents.forEach(content => {
                        content.classList.toggle('active', content.id === `tab-${tabId}`);
                    });
                });
            });

            const modal = document.getElementById('theme-modal');
            const openModalBtn = document.getElementById('open-modal-btn');
            const closeModalBtn = document.getElementById('close-modal-btn');
            const themeGrid = document.getElementById('theme-grid');
            const step1PromptCodeElement = document.getElementById('step1-prompt-code');

            async function loadThemes() {
                try {
                    // In a real environment, you would fetch a themes.json file.
                    // For this example, we'll use a static array.
                    const response = await fetch('themes.json');
                    if (!response.ok) {
                        throw new Error(`HTTP error! status: ${response.status}`);
                    }
                    const themesData = await response.json();
                    
                    themeGrid.innerHTML = '';
                    themesData.sort((a, b) => a.title.localeCompare(b.title, 'ko')).forEach(theme => {
                        const card = document.createElement('div');
                        card.className = 'modal-card bg-slate-50 p-4 rounded-lg cursor-pointer border hover:border-amber-500 hover:bg-amber-50';
                        card.innerHTML = `<div class="text-3xl mb-2">${theme.emoji}</div><h3 class="font-bold text-slate-800">${theme.title}</h3><p class="text-sm text-slate-600 mt-1">${theme.description}</p>`;
                        card.addEventListener('click', () => {
                            const basePrompt = `You are a creative game designer. Based on the theme "[THEME_PLACEHOLDER]", please develop a detailed and engaging game plan...`;
                            const promptToCopy = basePrompt.replace('[THEME_PLACEHOLDER]', `"${theme.rl_concept}"`);
                            if(step1PromptCodeElement) step1PromptCodeElement.textContent = promptToCopy;
                            navigator.clipboard.writeText(promptToCopy).then(() => {
                                 alert(`'${theme.title}' 주제의 프롬프트가 클립보드에 복사되었습니다.`);
                            });
                            if(modal) modal.classList.add('hidden');
                        });
                        themeGrid.appendChild(card);
                    });
                } catch (error) { 
                    console.error("Could not load themes.json:", error); 
                    if(themeGrid) themeGrid.innerHTML = '<p class="text-red-500 col-span-3">themes.json 파일을 찾을 수 없습니다.</p>';
                }
            }

            if(modal && openModalBtn && closeModalBtn) {
                 openModalBtn.addEventListener('click', () => modal.classList.remove('hidden'));
                 closeModalBtn.addEventListener('click', () => modal.classList.add('hidden'));
                 modal.addEventListener('click', (e) => { if (e.target.id === 'theme-modal') modal.classList.add('hidden'); });
                loadThemes();
            }
        });
    </script>
</body>
</html>

