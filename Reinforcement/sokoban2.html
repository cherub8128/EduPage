<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>소코반 AI 업그레이드: CNN과 RND 적용하기</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-okaidia.min.css">
    <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+KR:wght@400;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Noto Sans KR', sans-serif;
            background-color: #282c34;
            color: #abb2bf;
        }
        .slide {
            display: none;
        }
        .slide.active {
            display: block;
        }
        .code-highlight {
            background-color: rgba(255, 255, 0, 0.15);
            display: block;
            margin: -0.25rem -0.5rem;
            padding: 0.25rem 0.5rem;
            border-radius: 0.25rem;
        }
        pre[class*="language-"] {
            font-size: 0.9rem;
            line-height: 1.6;
            white-space: pre-wrap;
            word-break: break-all;
            overflow-x: auto;
        }
        .explanation-box {
            background-color: #21252b;
            border-left: 4px solid #61afef;
            padding: 1rem;
            border-radius: 0.5rem;
            margin-top: 1rem;
        }
        /* CNN Animation Styles */
        .cnn-container {
            display: flex;
            justify-content: center;
            align-items: center;
            gap: 20px;
            margin-top: 20px;
            min-height: 200px;
            flex-wrap: wrap;
        }
        .grid-container {
            position: relative;
        }
        .cnn-grid {
            display: grid;
            border: 2px solid #61afef;
        }
        .input-grid {
            grid-template-columns: repeat(5, 30px);
            grid-template-rows: repeat(5, 30px);
        }
        .cell {
            width: 30px;
            height: 30px;
            border: 1px solid #4a5568;
            display: flex;
            justify-content: center;
            align-items: center;
            font-size: 14px;
            font-weight: bold;
            color: #e5c07b;
        }
        .kernel {
            position: absolute;
            top: 0;
            left: 0;
            width: 90px;
            height: 90px;
            border: 2px solid #e5c07b;
            background-color: rgba(229, 192, 123, 0.2);
            animation: scanAnimation 9s infinite steps(1, end);
        }
        .output-grid {
            grid-template-columns: repeat(3, 30px);
            grid-template-rows: repeat(3, 30px);
        }
        .output-marker {
            position: absolute;
            top: 0;
            left: 0;
            width: 30px;
            height: 30px;
            background-color: rgba(97, 175, 239, 0.5);
            border: 2px solid #61afef;
            animation: outputAnimation 9s infinite steps(1, end);
        }

        @keyframes scanAnimation {
            0%      { transform: translate(0px, 0px); }
            11.1%   { transform: translate(30px, 0px); }
            22.2%   { transform: translate(60px, 0px); }
            33.3%   { transform: translate(0px, 30px); }
            44.4%   { transform: translate(30px, 30px); }
            55.5%   { transform: translate(60px, 30px); }
            66.6%   { transform: translate(0px, 60px); }
            77.7%   { transform: translate(30px, 60px); }
            88.8%   { transform: translate(60px, 60px); }
            100%    { transform: translate(60px, 60px); }
        }
        @keyframes outputAnimation {
            0%      { transform: translate(0px, 0px); }
            11.1%   { transform: translate(30px, 0px); }
            22.2%   { transform: translate(60px, 0px); }
            33.3%   { transform: translate(0px, 30px); }
            44.4%   { transform: translate(30px, 30px); }
            55.5%   { transform: translate(60px, 30px); }
            66.6%   { transform: translate(0px, 60px); }
            77.7%   { transform: translate(30px, 60px); }
            88.8%   { transform: translate(60px, 60px); }
            100%    { transform: translate(60px, 60px); }
        }
    </style>
</head>
<body class="p-4 md:p-8">

    <div class="max-w-7xl mx-auto bg-[#21252b] rounded-xl shadow-2xl overflow-hidden">
        <div class="p-8">
            <h1 class="text-3xl md:text-4xl font-bold text-white text-center">소코반 AI 업그레이드: CNN과 RND 적용하기</h1>
            <p class="text-center text-gray-400 mt-2">단순한 모델을 넘어, 스스로 탐험하는 똑똑한 AI를 만들어봅니다.</p>
        </div>

        <div id="slider-container" class="p-4 md:p-8 border-t border-gray-700 min-h-[500px]">
            <!-- Slides will be injected here by JS -->
        </div>

        <div class="bg-[#282c34] p-4 flex justify-between items-center">
            <button id="prevBtn" class="bg-gray-600 hover:bg-gray-500 text-white font-bold py-2 px-4 rounded-lg transition duration-300 disabled:opacity-50 disabled:cursor-not-allowed">이전</button>
            <div id="slide-counter" class="text-white text-lg font-semibold"></div>
            <button id="nextBtn" class="bg-indigo-600 hover:bg-indigo-500 text-white font-bold py-2 px-4 rounded-lg transition duration-300">다음</button>
        </div>
    </div>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
    <script>
        const slides = [
            {
                title: "1. 왜 업그레이드가 필요한가요?",
                explanation: `
                    <p>이전 버전의 AI는 게임 상태(숫자 그리드)를 하나의 긴 목록으로 보고 학습했습니다. 이는 <strong>'어떤 타일이 어디에 있는지'</strong>는 알지만, <strong>'어떤 타일이 서로 이웃해 있는지'</strong>와 같은 공간적인 관계를 파악하기 어렵습니다.</p>
                    <p class="mt-2">소코반처럼 객체들의 위치 관계가 중요한 게임에서는 이 한계가 명확합니다. 이를 해결하기 위해 두 가지 강력한 기술을 도입합니다.</p>
                    <div class="explanation-box">
                        <p><strong>1. Custom CNN (Convolutional Neural Network):</strong> 이미지처럼 2D 공간 정보를 잘 처리하는 '눈' 역할을 하는 신경망을 사용합니다.</p>
                        <p class="mt-2"><strong>2. RND (Random Network Distillation):</strong> 보상이 드문 소코반 게임에서 AI가 지루해하지 않고 스스로 '호기심'을 갖고 탐험하도록 만드는 기술입니다.</p>
                    </div>
                `,
                code: ``
            },
            {
                title: "2. CNN의 원리: 세상을 보는 새로운 눈",
                explanation: `
                    <p>CNN은 '필터(커널)'라는 작은 돋보기를 사용해 이미지의 특징을 찾아냅니다. 이 돋보기를 이미지 전체에 훑으면서(Convolution), 선, 모서리, 질감 같은 간단한 특징부터 시작해 점점 더 복잡한 형태를 인식하게 됩니다.</p>
                    <p class="mt-2">아래 애니메이션은 3x3 필터(노란색)가 5x5 입력 데이터(게임 맵)를 훑으며 3x3 특징 맵(오른쪽)을 만들어내는 과정을 시각화한 것입니다. 출력 그리드의 파란색 하이라이트는 현재 계산되고 있는 위치를 나타냅니다.</p>
                    <div class="cnn-container">
                        <div class="grid-container">
                            <div class="cnn-grid input-grid">
                                ${Array.from({length: 25}).map((_, i) => `<div class="cell">${Math.floor(Math.random()*5)}</div>`).join('')}
                            </div>
                            <div class="kernel"></div>
                        </div>
                        <div class="text-4xl text-indigo-400">&rarr;</div>
                        <div class="grid-container">
                             <div class="cnn-grid output-grid">
                                ${Array.from({length: 9}).map(() => `<div class="cell">?</div>`).join('')}
                            </div>
                            <div class="output-marker"></div>
                        </div>
                    </div>
                `,
                code: ``
            },
            {
                title: "3. CNN의 적용을 위한 환경 코드 수정",
                explanation: `
                    <p>CNN은 '필터(커널)'라는 작은 돋보기를 사용해 이미지의 특징을 찾아냅니다. 이 돋보기를 이미지 전체에 훑으면서(Convolution), 선, 모서리, 질감 같은 간단한 특징부터 시작해 점점 더 복잡한 형태를 인식하게 됩니다.</p>
                    <p class="mt-2">아래 애니메이션은 3x3 필터(노란색)가 5x5 입력 데이터(게임 맵)를 훑으며 3x3 특징 맵(오른쪽)을 만들어내는 과정을 시각화한 것입니다. 출력 그리드의 파란색 하이라이트는 현재 계산되고 있는 위치를 나타냅니다.</p>
                    <div class="cnn-container">
                        <div class="grid-container">
                            <div class="cnn-grid input-grid">
                                ${Array.from({length: 25}).map((_, i) => `<div class="cell">${Math.floor(Math.random()*5)}</div>`).join('')}
                            </div>
                            <div class="kernel"></div>
                        </div>
                        <div class="text-4xl text-indigo-400">&rarr;</div>
                        <div class="grid-container">
                             <div class="cnn-grid output-grid">
                                ${Array.from({length: 9}).map(() => `<div class="cell">?</div>`).join('')}
                            </div>
                            <div class="output-marker"></div>
                        </div>
                    </div>
                `,
                code: `
# __init__ 함수에 수정된 부분
self.observation_space = spaces.Box(
    low=0, high=4,
    shape=(1, self.game.map_height, self.game.map_width), # shape 변경
    dtype=np.uint8
)

# step 함수에 수정된 부분
obs_with_channel = np.expand_dims(obs, axis=0)
return obs_with_channel, reward, terminated, truncated, {}
`
            },
            {
                title: "4. Stable-Baselines3를 위한 Custom CNN 구현",
                explanation: `
                    <p>Stable-Baselines3는 기본 CNN 구조를 제공하지만, 우리만의 맞춤형 CNN 구조를 만들어 사용할 수 있습니다. <code class="bg-gray-700 p-1 rounded">BaseFeaturesExtractor</code>를 상속받아 간단한 CNN 클래스를 정의합니다.</p>
                    <p class="mt-2">이 코드는 2개의 합성곱 레이어(Conv2d)와 1개의 완전 연결 레이어(Linear)로 구성된 간단한 CNN입니다. 이 네트워크가 게임 그리드를 입력받아 핵심 특징을 추출하는 역할을 합니다.</p>
                `,
                code: `
import torch
import torch.nn as nn
from gymnasium import spaces
from stable_baselines3.common.torch_layers import BaseFeaturesExtractor

class CustomCNN(BaseFeaturesExtractor):
    def __init__(self, observation_space: spaces.Box, features_dim: int = 128):
        super().__init__(observation_space, features_dim)
        # 관찰 공간의 shape는 (height, width, channels) -> (H, W, C)
        # PyTorch의 Conv2d는 (N, C, H, W)를 기대하므로 채널 수를 마지막 차원에서 가져옵니다.
        n_input_channels = observation_space.shape[2] 
        self.cnn = nn.Sequential(
            nn.Conv2d(n_input_channels, 32, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.Flatten(),
        )
        # CNN 출력 크기를 계산하여 Linear 레이어에 연결
        with torch.no_grad():
            # (H, W, C) -> (N, C, H, W) 형태로 변환하여 테스트
            sample_input = torch.as_tensor(observation_space.sample()[None]).permute(0, 3, 1, 2).float()
            n_flatten = self.cnn(sample_input).shape[1]
        
        self.linear = nn.Sequential(nn.Linear(n_flatten, features_dim), nn.ReLU())

    def forward(self, observations: torch.Tensor) -> torch.Tensor:
        # (N, H, W, C) -> (N, C, H, W)
        observations = observations.permute(0, 3, 1, 2)
        return self.linear(self.cnn(observations))
                `
            },
            {
                title: "5. 문제점: 희소한 보상 (Sparse Rewards)",
                explanation: `
                    <p>소코반 게임은 '박스를 목표 지점에 정확히 밀어 넣었을 때'만 큰 보상을 받습니다. 그 외의 수많은 움직임은 보상이 거의 없거나 작은 페널티만 있죠. 이런 환경을 <strong>희소 보상 환경</strong>이라고 합니다.</p>
                    <p class="mt-2">AI는 우연히 박스를 목표에 밀기 전까지는 어떤 행동이 좋은지 전혀 알 수 없어, 학습 초기에 길을 잃고 헤매기 쉽습니다. 마치 어두운 방에서 출구를 찾는 것과 같습니다.</p>
                    <div class="explanation-box">
                        <p><strong>해결책: 내재적 동기부여 (Intrinsic Motivation)</strong><br>
                        AI에게 '호기심'이라는 내재적 보상을 주어, 외부 보상이 없어도 스스로 새로운 것을 탐험하도록 유도합니다.</p>
                    </div>
                `,
                code: ``
            },
            {
                title: "6. RND: '새로움'을 보상으로",
                explanation: `
                    <p><strong>Random Network Distillation (RND)</strong>은 AI의 호기심을 구현하는 대표적인 방법입니다.</p>
                    <p class="mt-2">두 개의 신경망을 사용합니다:</p>
                    <ul class="list-disc list-inside space-y-2 mt-2">
                        <li><strong>선생님 망 (Target Network):</strong> 무작위로 생성되어 절대 변하지 않습니다.</li>
                        <li><strong>학생 망 (Predictor Network):</strong> 선생님 망의 출력을 따라하도록 학습합니다.</li>
                    </ul>
                    <p class="mt-2">AI가 <strong>이미 가본 곳(익숙한 상태)</strong>을 입력하면, 학생 망은 선생님 망의 출력을 쉽게 예측합니다 (오차 작음). 하지만 <strong>처음 가보는 곳(새로운 상태)</strong>을 입력하면, 예측을 잘 못해서 큰 오차가 발생합니다. <strong>이 예측 오차(prediction error)를 '호기심 보상'으로 사용합니다.</strong></p>
                `,
                code: `
# RND의 핵심 원리
# reward_intrinsic = || predictor_network(state) - target_network(state) ||²

# 처음 보는 상태일수록 예측 오차가 커져서 보상이 높아짐
# -> AI는 높은 보상을 받기 위해 새로운 상태를 찾아다니게 됨
                `
            },
            {
                title: "7. RND 구현하기 (sb3-contrib)",
                explanation: `
                    <p>RND는 직접 구현이 필요합니다. 현재의 지식으로는 직접 구현이 어려우니, 이미 구현된 코드를 사용하겠습니다.</p>
                    <p class="mt-2">링크의 파일을 다운로드하여 같은 폴더에 넣고 임포트하여, 기존에 만들었던 PPO 모델을 <code class="bg-gray-700 p-1 rounded">RND</code> 클래스로 한번 감싸주기만 하면 됩니다.</p>
                    <div class="my-4">
                        <a id="download-link" href="rnd_wrapper.py" download="rnd_wrapper.py" class="inline-block bg-teal-500 hover:bg-teal-400 text-white font-bold py-2 px-4 rounded-lg transition duration-300">
                            rnd_wrapper.py 다운로드
                        </a>
                    </div>
                `,
                code: `
# 환경 생성을 위한 헬퍼 함수
def make_env(log_dir):
    def _init():
        env = SokobanEnv()
        # RND 래퍼를 적용합니다.
        env = RNDRewardWrapper(env, lr=1e-4, feature_dim=128)
        env = Monitor(env, log_dir)
        return env
    return _init
                `
            },
            {
                title: "8. 최종 학습 코드 (sokoban_train_advanced.py)",
                explanation: `
                    <p>지금까지 배운 Custom CNN과 RND를 모두 적용한 최종 학습 스크립트입니다. 이 코드를 Colab에 붙여넣고 실행하면, 똑똑해진 소코반 AI의 학습이 시작됩니다.</p>
                    <div class="explanation-box">
                        <p><strong>주요 변경점:</strong><br>
                        - 환경의 관찰을 이미지에 맞게 채널 우선(Channel-first)으로 변경합니다.<br>
                        - PPO 모델 생성 시 <code class="bg-gray-700 p-1 rounded">policy_kwargs</code>로 CustomCNN을 지정합니다.<br>
                        - PPO 모델을 <code class="bg-gray-700 p-1 rounded">RND</code>로 감싸서 최종 모델을 만듭니다.<br>
                        - RND는 많은 탐험이 필요하므로 <code class="bg-gray-700 p-1 rounded">total_timesteps</code>를 크게 설정합니다.
                        </p>
                    </div>
                    <div class="my-4">
                        <a id="download-link" href="sokoban_env.py" download="sokoban_env.py" class="inline-block bg-teal-500 hover:bg-teal-400 text-white font-bold py-2 px-4 rounded-lg transition duration-300">
                            sokoban_env.py 완성 파일 다운로드
                        </a>
                    </div>
                `,
                code: `
import os
import torch
import torch.nn as nn
from gymnasium import spaces

from stable_baselines3 import PPO
from stable_baselines3.common.monitor import Monitor
from stable_baselines3.common.vec_env import DummyVecEnv
from stable_baselines3.common.torch_layers import BaseFeaturesExtractor
from stable_baselines3.common.callbacks import CheckpointCallback

from rnd_wrapper import RNDRewardWrapper 
from sokoban_env import SokobanEnv

class CustomCNN(BaseFeaturesExtractor):
    def __init__(self, observation_space: spaces.Box, features_dim: int = 128):
        super().__init__(observation_space, features_dim)
        n_input_channels = observation_space.shape[0]
        self.cnn = nn.Sequential(
            nn.Conv2d(n_input_channels, 32, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.Flatten(),
        )
        with torch.no_grad():
            n_flatten = self.cnn(
                torch.as_tensor(observation_space.sample()[None]).float()
            ).shape[1]
        self.linear = nn.Sequential(nn.Linear(n_flatten, features_dim), nn.ReLU())

    def forward(self, observations: torch.Tensor) -> torch.Tensor:
        return self.linear(self.cnn(observations))


# 환경 생성을 위한 헬퍼 함수
def make_env(log_dir):
    def _init():
        env = SokobanEnv()
        # RND 래퍼를 적용합니다.
        env = RNDRewardWrapper(env, lr=1e-4, feature_dim=128)
        env = Monitor(env, log_dir)
        return env
    return _init

if __name__ == '__main__':
    log_dir = "sokoban_logs_rnd_manual/"
    tensorboard_log_dir = "sokoban_tensorboard_rnd_manual/"
    model_save_path = "sokoban_models_rnd_manual/"

    os.makedirs(log_dir, exist_ok=True)
    os.makedirs(tensorboard_log_dir, exist_ok=True)
    os.makedirs(model_save_path, exist_ok=True)

    env = DummyVecEnv([make_env(log_dir)])

    policy_kwargs = dict(
        features_extractor_class=CustomCNN,
        features_extractor_kwargs=dict(features_dim=128),
    )

    # RND 래퍼가 보상을 처리해주므로, 일반 PPO 모델을 사용합니다.
    model = PPO(
        "CnnPolicy",
        env,
        policy_kwargs=policy_kwargs,
        verbose=1,
        tensorboard_log=tensorboard_log_dir,
        learning_rate=3e-4,
        n_steps=2048,
        batch_size=128, # RND 사용 시 배치 사이즈를 늘리면 안정적일 수 있습니다.
        n_epochs=10,
        gamma=0.99,
        ent_coef=0.01,
    )
    
    checkpoint_callback = CheckpointCallback(
        save_freq=50000,
        save_path=model_save_path,
        name_prefix="sokoban_rnd_manual_model"
    )

    print("--- 직접 구현한 RND를 사용한 학습 시작 ---")
    model.learn(
        total_timesteps=1_000_000,
        callback=checkpoint_callback,
        progress_bar=True
    )

    final_model_path = os.path.join(model_save_path, "sokoban_rnd_manual_final")
    model.save(final_model_path)
    
    env.close()

    print("\n" + "="*50)
    print("🎉 학습이 성공적으로 완료되었습니다!")
    print(f"최종 모델은 '{final_model_path}.zip'에 저장되었습니다.")
    print("학습 과정을 확인하려면 아래 명령어를 터미널에 입력하세요:")
    print(f"tensorboard --logdir={tensorboard_log_dir}")
    print("="*50)
                `
            }
        ];

        let currentSlide = 0;
        const sliderContainer = document.getElementById('slider-container');
        const prevBtn = document.getElementById('prevBtn');
        const nextBtn = document.getElementById('nextBtn');
        const slideCounter = document.getElementById('slide-counter');

        function createSlide(slideData, index) {
            const slideElement = document.createElement('div');
            slideElement.className = 'slide p-4';
            slideElement.dataset.index = index;

            let codeHtml = '';
            if (slideData.code) {
                // To prevent Prism from misinterpreting the HTML-like syntax in the code,
                // we replace angle brackets with their HTML entities before passing to Prism.
                const escapedCode = slideData.code.trim()
                    .replace(/</g, '&lt;')
                    .replace(/>/g, '&gt;');
                
                // Then, we replace our custom highlight tags with actual span tags.
                const finalCode = escapedCode
                    .replace(/\[\[HIGHLIGHT_START\]\]/g, '<span class="code-highlight">')
                    .replace(/\[\[HIGHLIGHT_END\]\]/g, '</span>');

                codeHtml = `<div class="mt-6 bg-[#282c34] rounded-lg overflow-hidden border border-gray-700"><pre class="language-python !text-sm !leading-relaxed"><code>${finalCode}</code></pre></div>`;
            }

            slideElement.innerHTML = `<div class="grid grid-cols-1 ${slideData.code ? 'md:grid-cols-2' : ''} gap-8 items-start"><div class="max-w-none prose prose-invert"><h2 class="text-2xl font-bold text-indigo-400 mb-4">${slideData.title}</h2><div class="text-gray-300 leading-relaxed space-y-2">${slideData.explanation}</div></div>${slideData.code ? `<div>${codeHtml}</div>` : ''}</div>`;
            return slideElement;
        }

        function updateSlider() {
            document.querySelectorAll('.slide').forEach((slide, index) => {
                slide.classList.toggle('active', index === currentSlide);
            });
            slideCounter.textContent = `${currentSlide + 1} / ${slides.length}`;
            prevBtn.disabled = currentSlide === 0;
            nextBtn.disabled = currentSlide === slides.length - 1;
            Prism.highlightAll();
        }

        prevBtn.addEventListener('click', () => { if (currentSlide > 0) { currentSlide--; updateSlider(); } });
        nextBtn.addEventListener('click', () => { if (currentSlide < slides.length - 1) { currentSlide++; updateSlider(); } });
        
        slides.forEach((slideData, index) => { sliderContainer.appendChild(createSlide(slideData, index)); });
        updateSlider();
    </script>
</body>
</html>
