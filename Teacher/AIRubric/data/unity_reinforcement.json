{
  "overview": {
    "task": "직접 만든 아주 간단한 유니티 게임의 강화학습 환경(예: 그리드 이동·장애물 회피·간단 수집 게임 등)으로 관측/행동/보상을 설계하고, SB3(PPO/A2C/DQN 등)로 학습·튜닝·평가 후 결과를 시연 및 요약 보고로 정리한다.\n- 권장 산출물: 코드 저장소(README, 실행 스크립트), 학습 로그/그래프, 20–60초 시연 영상 또는 GIF, 1–2쪽 요약 보고(문제–설계–학습–평가–배운 점)",
    "standards": "[12인기02-04] 퍼즐·게임 문제 해결을 위한 탐색/상태 구조화\n[12인기02-05] 최상우선/휴리스틱 사고를 통해 경로·정책 탐색의 중요성 인식\n[12인기02-09] 딥러닝을 활용한 정책/가치 근사 이해와 적용\n[12인기03-08] 평가 프로토콜 수립 및 재현성 있는 성능 보고",
    "ideas": "환경 우선: 관측/행동공간을 단순·명확하게 정의하고, 보상은 짧고 일관되게 설계\n작게 빨리: 짧은 학습·빠른 피드백으로 하이퍼/보상 한 가지씩 실험해 개선점 찾기\n재현성: 시드·버전·평가 횟수 고정, 로그·그래프로 누가 해도 같은 결과에 가깝게\n가독성: 실행법·결과 요약을 한 눈에 보이도록 정리",
    "criteria": {
      "type": "5-point",
      "levels": {
        "A": "환경–학습–평가 흐름을 유기적으로 통합하고, 간단한 튜닝·비교로 타당한 결론과 개선안을 제시한다.",
        "B": "핵심 요소를 충실히 구현·연결하고, 일부 하이퍼/보상 변경으로 의미 있는 관찰을 제시한다.",
        "C": "기본 환경을 구현·학습·평가하고, 로그·그래프로 결과를 분명히 설명한다.",
        "D": "실행 가능한 흐름을 만들고, 다음에 시도할 학습·테스트 계획을 정리한다.",
        "E": "꾸준히 참여하며 핵심 절차와 배운 점을 기록해 다음 단계의 기반을 마련한다."
      }
    }
  },
  "rubric": [
    {
      "name": "환경 설계·구현",
      "type": "single",
      "scores": {
        "득점": 5
      },
      "descriptions": {
        "득점": "관측/행동/보상 설계를 정리하고 안정 실행, 예외 처리와 간단 리셋/종료 로직을 갖춘다."
      }
    },
    {
      "name": "학습·튜닝",
      "type": "single",
      "scores": {
        "득점": 5
      },
      "descriptions": {
        "득점": "알고리즘(PPO/A2C/DQN 등) 선택 근거를 적고, 하이퍼 2가지 이상을 비교하여 간단 표/그래프로 제시한다."
      }
    },
    {
      "name": "테스트·평가",
      "type": "single",
      "scores": {
        "득점": 5
      },
      "descriptions": {
        "득점": "평가 프로토콜(시드·에피소드 수)을 정해 두 번 이상 반복 측정하고 평균/분포를 비교한다."
      }
    },
    {
      "name": "소통·산출물 (README/ 시연/요약)",
      "type": "single",
      "scores": {
        "득점": 5
      },
      "descriptions": {
        "득점": "실행법과 결과를 1페이지 요약+30–60초 시연 영상/GIF로 정리하고 다음 개선 1가지를 제안한다."
      }
    }
  ]
}